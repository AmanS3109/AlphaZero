# ğŸ§  AlphaZero from Scratch

A from-scratch implementation of AlphaZero, showcasing powerful tree search and deep learning techniques for playing board games like **TicTacToe** and **Connect Four**. Built with **PyTorch**, **NumPy**, and custom UIs, this project explores and compares different variants of **Monte Carlo Tree Search (MCTS)** â€” including **AlphaMCTS** and their **parallelized versions** â€” with a focus on **speed optimization** and **strategic play**.

---

## ğŸš€ Features

- âœ… **Pure Python implementation** (no external RL libraries)
- â™Ÿï¸ **Two classic games**: TicTacToe and Connect Four
- ğŸ§® **Algorithms implemented**:
  - Standard MCTS
  - AlphaMCTS (neural-guided MCTS)
  - MCTSParallel
  - AlphaMCTSParallel
- âš¡ **Optimized for speed** using multiprocessing in Python
- ğŸ“Š **Matplotlib visualizations** of training statistics
- ğŸ¤– **Evaluation using Kaggle Environments** (agents compete against each other)
- ğŸ–¼ï¸ Simple **Python-based UI** to play against trained agents

---

## ğŸ§± Tech Stack

- **Python**
- **PyTorch**
- **NumPy**
- **Matplotlib**
- **Kaggle Environments**

---

## ğŸ“‚ Project Structure

```bash
alphazero/
â”‚
â”œâ”€â”€ agents/              # MCTS and AlphaMCTS (standard + parallel)
â”œâ”€â”€ games/               # TicTacToe and ConnectFour logic
â”œâ”€â”€ model/               # ResNet model using PyTorch
â”œâ”€â”€ self_play/           # Self-play and training loop
â”œâ”€â”€ ui/                  # Simple game UIs for human-vs-AI
â”œâ”€â”€ evaluation/          # Evaluation scripts (including Kaggle Env)
â”œâ”€â”€ utils/               # Helper functions
â”œâ”€â”€ notebooks/           # Jupyter notebooks for training logs, experiments
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
